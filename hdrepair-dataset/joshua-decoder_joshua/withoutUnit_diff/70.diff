diff --git a/aexperiment/example.config.HG.javalm b/aexperiment/example.config.HG.javalm
new file mode 100644
index 0000000..901a02f
--- /dev/null
+++ b/aexperiment/example.config.HG.javalm
@@ -0,0 +1,134 @@
+lm_file=example2/example2.4gram.lm.gz
+#lm_file=C:/data_disk/java_work_space/sf_trunk/example/example.trigram.lm.gz
+
+tm_file=example/example.hiero.tm.gz
+tm_format=hiero
+
+glue_file=grammars/hiero.glue
+glue_format=hiero
+
+#lm config
+use_srilm=false
+lm_ceiling_cost=100
+use_left_euqivalent_state=false
+use_right_euqivalent_state=false
+order=4
+
+
+#tm config
+span_limit=10
+phrase_owner=pt
+mono_owner=mono
+begin_mono_owner=begin_mono
+default_non_terminal=X
+goalSymbol=S
+
+#pruning config
+useCubePrune=true
+useBeamAndThresholdPrune=true
+fuzz1=0.1
+fuzz2=0.1
+max_n_items=30
+relative_threshold=10.0
+max_n_rules=50
+rule_relative_threshold=10.0
+
+#nbest config
+use_unique_nbest=true
+use_tree_nbest=false
+add_combined_cost=true
+top_n=300
+
+
+#remoter lm server config,we should first prepare remote_symbol_tbl before starting any jobs
+use_remote_lm_server=false
+remote_symbol_tbl=./voc.remote.sym
+num_remote_lm_servers=4
+f_remote_server_list=./remote.lm.server.list
+remote_lm_server_port=9000
+
+
+#parallel deocoder: it cannot be used together with remote lm
+num_parallel_decoders=2
+parallel_files_prefix=.
+
+#disk hg
+save_disk_hg=true
+forest_pruning=false
+forest_pruning_threshold=150
+
+
+###### model weights
+#lm order weight
+lm 1.000000
+
+#phrasemodel owner column(0-indexed) weight
+phrasemodel pt 0 1.066893
+phrasemodel pt 1 0.752247
+phrasemodel pt 2 0.589793
+
+#arityphrasepenalty owner start_arity end_arity weight
+#arityphrasepenalty pt 0 0 1.0
+#arityphrasepenalty pt 1 2 -1.0
+
+#phrasemodel mono 0 0.5
+
+#wordpenalty weight
+wordpenalty -2.844814
+#latticecost 1.0
+
+
+#========================discriminative model options
+#discriminative C:\data_disk\java_work_space\discriminative_at_clsp\edu\jhu\joshua\training\risk_annealer\data\example.hiero.feature 1.0
+
+#general
+maxNumIter=2
+useSemiringV2=true
+maxNumHGInQueue=100
+numThreads=4
+saveHGInMemory=false
+
+
+#option for first feature (e.g., baseline feature)
+normalizeByFirstFeature=true
+fixFirstFeature=false
+
+
+#google linear corpus gain
+useGoogleLinearCorpusGain=true
+unigramPrecision=0.85
+precisionDecayRatio=0.7
+numUnigramTokens=10
+
+#annealing?
+annealingMode=0
+isScalingFactorTunable=false
+useL2Regula=false
+varianceForL2=1
+useModelDivergenceRegula=true
+lambda=-1
+
+#feature related
+#dense features
+useBaseline=false
+baselineFeatureName=baseline_lzf
+baselineFeatureWeight=1.0
+
+useIndividualBaselines=true
+numIndividualBaselines=5
+
+#sparse features
+useSparseFeature=false
+useTMFeat=true
+useRuleIDName=true
+useTMTargetFeat=false
+
+useLMFeat=false
+startNgramOrder=1
+endNgramOrder=2
+
+
+
+
+
+
diff --git a/src/joshua/discriminative/training/lbfgs/LBFGSWrapper.java b/src/joshua/discriminative/training/lbfgs/LBFGSWrapper.java
index 0194079..ea70f67 100644
--- a/src/joshua/discriminative/training/lbfgs/LBFGSWrapper.java
+++ b/src/joshua/discriminative/training/lbfgs/LBFGSWrapper.java
@@ -121 +121 @@
-        		this.doL2ForConditionalEntropy(resFuncVal, getCurWeightVector(), gradientVector, resFuncVal, this.lambda);
+        		this.doL2ForConditionalEntropy(this.initWeights, getCurWeightVector(), gradientVector, resFuncVal, this.lambda);

